{
 "cells": [
    "cell_type": "markdown",
      "metadata": {
        "id": "Fg-hHCYEX98V"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)]\n",
        "(https://colab.research.google.com/github/refugies-info/genai-for-public-good/blob/main/notebooks/Categorie_Classifier.ipynb)"
      ]
    },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from gdown) (4.13.3)\n",
      "Requirement already satisfied: filelock in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from gdown) (3.17.0)\n",
      "Requirement already satisfied: requests[socks] in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from beautifulsoup4->gdown) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from requests[socks]->gdown) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from requests[socks]->gdown) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from requests[socks]->gdown) (2025.1.31)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1z-SRYUL6bAHQ-vfP0AJgxMjpkCd-56iP\n",
      "To: /home/onyxia/work/genai-for-public-good/notebooks/ri_annotated_texts_final.csv\n",
      "  0%|                                               | 0.00/76.8k [00:00<?, ?B/s]Error:\n",
      "\n",
      "\t[Errno 28] No space left on device\n",
      "\n",
      "To report issues, please visit https://github.com/wkentaro/gdown/issues.\n",
      "  0%|                                               | 0.00/76.8k [00:00<?, ?B/s]\n",
      "Requirement already satisfied: datasets in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (3.2.0)\n",
      "Requirement already satisfied: transformers in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (4.48.2)\n",
      "Requirement already satisfied: evaluate in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: sentencepiece in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: accelerate in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (1.3.0)\n",
      "Requirement already satisfied: filelock in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: packaging in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: psutil in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: networkx in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "!gdown \"https://drive.google.com/uc?id=1z-SRYUL6bAHQ-vfP0AJgxMjpkCd-56iP\"\n",
    "\n",
    "!pip install datasets transformers evaluate sentencepiece accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = 'ri_annotated_texts_final.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning\n",
    "def clean_text(text:str):\n",
    "    import re\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"^-\\s+\", \"\", text)\n",
    "    return text\n",
    "data[\"Version initiale\"] = data[\"Version initiale\"].apply(clean_text)\n",
    "data[\"Version retraitée\"] = data[\"Version retraitée\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Compression',\n",
       " 'Explanation',\n",
       " 'Modulation',\n",
       " 'Omission',\n",
       " 'Substitution',\n",
       " 'Synonymy',\n",
       " 'Syntactic',\n",
       " 'Transcription',\n",
       " 'Transposition']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.groupby(by=\"Version initiale\").aggregate({\"Version retraitée\":'first', \"Catégorie\":lambda x: \", \".join(x)}).reset_index(drop=False)\n",
    "classes = sorted(list(set(\", \".join(data[\"Catégorie\"]).split(\", \"))))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version initiale</th>\n",
       "      <th>Version retraitée</th>\n",
       "      <th>Catégorie</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173h de formation en français pour étrangers d...</td>\n",
       "      <td>Des cours de français pour débutants, 4 après-...</td>\n",
       "      <td>Explanation, Substitution</td>\n",
       "      <td>[1, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96h de français pour apprendre à communiquer à...</td>\n",
       "      <td>96 heures de français pour progresser à l'oral...</td>\n",
       "      <td>Substitution</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accompagnement et conseils pendant et après la...</td>\n",
       "      <td>Accompagnement et conseils pendant et après la...</td>\n",
       "      <td>Transcription</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accompagnement individuel</td>\n",
       "      <td>Accompagnement individuel</td>\n",
       "      <td>Transcription</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accompagnement pour les démarches</td>\n",
       "      <td>Accompagnement pour les démarches</td>\n",
       "      <td>Transcription</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>savoir se présenter et se comporter en entrepr...</td>\n",
       "      <td>savoir se présenter et avoir la bonne attitude...</td>\n",
       "      <td>Substitution</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>une découverte du chantier et des métiers poss...</td>\n",
       "      <td>une découverte du chantier et des métiers poss...</td>\n",
       "      <td>Transcription</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>une présentation des métiers recherchés par le...</td>\n",
       "      <td>une présentation des métiers recherchés par le...</td>\n",
       "      <td>Transcription</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>vos coordonnées</td>\n",
       "      <td>votre nom et votre numéro</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>être grande débutant en français (écrit et oral)</td>\n",
       "      <td>être grand débutant en français (écrit et oral)</td>\n",
       "      <td>Transcription</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Version initiale  \\\n",
       "0    173h de formation en français pour étrangers d...   \n",
       "1    96h de français pour apprendre à communiquer à...   \n",
       "2    Accompagnement et conseils pendant et après la...   \n",
       "3                            Accompagnement individuel   \n",
       "4                    Accompagnement pour les démarches   \n",
       "..                                                 ...   \n",
       "252  savoir se présenter et se comporter en entrepr...   \n",
       "253  une découverte du chantier et des métiers poss...   \n",
       "254  une présentation des métiers recherchés par le...   \n",
       "255                                    vos coordonnées   \n",
       "256   être grande débutant en français (écrit et oral)   \n",
       "\n",
       "                                     Version retraitée  \\\n",
       "0    Des cours de français pour débutants, 4 après-...   \n",
       "1    96 heures de français pour progresser à l'oral...   \n",
       "2    Accompagnement et conseils pendant et après la...   \n",
       "3                            Accompagnement individuel   \n",
       "4                    Accompagnement pour les démarches   \n",
       "..                                                 ...   \n",
       "252  savoir se présenter et avoir la bonne attitude...   \n",
       "253  une découverte du chantier et des métiers poss...   \n",
       "254  une présentation des métiers recherchés par le...   \n",
       "255                          votre nom et votre numéro   \n",
       "256    être grand débutant en français (écrit et oral)   \n",
       "\n",
       "                     Catégorie classes  \n",
       "0    Explanation, Substitution  [1, 4]  \n",
       "1                 Substitution     [4]  \n",
       "2                Transcription     [7]  \n",
       "3                Transcription     [7]  \n",
       "4                Transcription     [7]  \n",
       "..                         ...     ...  \n",
       "252               Substitution     [4]  \n",
       "253              Transcription     [7]  \n",
       "254              Transcription     [7]  \n",
       "255                Explanation     [1]  \n",
       "256              Transcription     [7]  \n",
       "\n",
       "[257 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2id = {class_:id_ for id_, class_ in enumerate(classes)}\n",
    "id2class = {id_:class_ for class_, id_ in class2id.items()}\n",
    "\n",
    "data[\"classes\"] = [[class2id[g] for g in j.split(\", \")] for j in data[\"Catégorie\"]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Step 2: MultiLabel Binarization\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_binarized = mlb.fit_transform(data['classes'])\n",
    "texts = data['Version initiale'] + \" [SEP] \" + data['Version retraitée']\n",
    "\n",
    "# Step 3: Train-test split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels_binarized, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 205/205 [00:00<00:00, 2178.70 examples/s]\n",
      "Map: 100%|██████████| 52/52 [00:00<00:00, 2946.91 examples/s]\n",
      "/home/onyxia/work/genai-for-public-good/.venv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_14410/3086137785.py:70: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input_ids', 'attention_mask')\n",
      "{'num_items_in_batch': None}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 77\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Step 10: Initialize and Train the Model\u001b[39;00m\n\u001b[1;32m     70\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CustomTrainer(\n\u001b[1;32m     71\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     72\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Evaluate the Model\u001b[39;00m\n\u001b[1;32m     80\u001b[0m evaluation_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/work/genai-for-public-good/.venv/lib/python3.12/site-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/genai-for-public-good/.venv/lib/python3.12/site-packages/transformers/trainer.py:2531\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2524\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2525\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2529\u001b[0m )\n\u001b[1;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2537\u001b[0m ):\n\u001b[1;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/work/genai-for-public-good/.venv/lib/python3.12/site-packages/transformers/trainer.py:3675\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3672\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3674\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3675\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3677\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3679\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3680\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3681\u001b[0m ):\n",
      "Cell \u001b[0;32mIn[7], line 51\u001b[0m, in \u001b[0;36mCustomTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\n\u001b[1;32m     50\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[0;32m---> 51\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m())\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (loss, outputs) \u001b[38;5;28;01mif\u001b[39;00m return_outputs \u001b[38;5;28;01melse\u001b[39;00m loss\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Define the Custom Model with Attention Layer\n",
    "class TaskSpecificMultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super(TaskSpecificMultiLabelClassifier, self).__init__()\n",
    "        self.base_model = AutoModel.from_pretrained(model_name)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=self.base_model.config.hidden_size, num_heads=8)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.base_model.config.hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_labels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        attn_output, _ = self.attention(cls_embedding.unsqueeze(0), cls_embedding.unsqueeze(0), cls_embedding.unsqueeze(0))\n",
    "        logits = self.classifier(attn_output.squeeze(0))\n",
    "        return logits\n",
    "\n",
    "# Step 5: Tokenizer and Model Initialization\n",
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "num_labels = len(classes)\n",
    "model = TaskSpecificMultiLabelClassifier(model_name, num_labels)\n",
    "\n",
    "# Step 6: Tokenization Function\n",
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    tokenized['labels'] = examples['labels']\n",
    "    return tokenized\n",
    "\n",
    "# Step 7: Prepare Datasets\n",
    "train_dataset = Dataset.from_dict({'text': train_texts, 'labels': train_labels.tolist()})\n",
    "val_dataset = Dataset.from_dict({'text': val_texts, 'labels': val_labels.tolist()})\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Step 8: Define Custom Trainer\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False,**kwargs):\n",
    "        print(tuple(inputs.keys()))\n",
    "        print(kwargs)\n",
    "        labels = inputs.get('labels')\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs\n",
    "        loss_fn = nn.BCELoss()\n",
    "        loss = loss_fn(logits, labels.float())\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Step 9: Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/safespace/results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "# Step 10: Initialize and Train the Model\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the Model\n",
    "evaluation_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", evaluation_results)\n",
    "\n",
    "# Save the Model and Tokenizer\n",
    "model.save_pretrained(\"./multi_label_classifier\")\n",
    "tokenizer.save_pretrained(\"./multi_label_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
